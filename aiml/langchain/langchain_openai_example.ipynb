{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f076eb0-1262-406e-a8ca-39ea944387b7",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This example demonstrates how to write simple Python code that calls an LLM API (OpenAI in this case) and processes the model’s response. It covers two approaches:\n",
    "1. Using the OpenAI Python SDK\n",
    "2. Using LangChain’s ChatOpenAI class\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "You can either use the paid OpenAI API platform, or run an open-source OpenAI model such as `gpt-oss-20b` locally through LM Studio (the method used in this example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76bee2f9-c2d8-4700-842f-fbcdb486b0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain-core in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (1.1.0)\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain) (1.0.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain) (2.12.4)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain-core) (0.4.47)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.10)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (4.11.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
      "  Using cached langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting SQLAlchemy<3.0.0,>=1.4.0 (from langchain-community)\n",
      "  Downloading sqlalchemy-2.0.44-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.5 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.13.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain-community)\n",
      "  Downloading numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.8.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.7.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.4.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.22.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (75 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
      "  Using cached langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community)\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain) (1.3.1)\n",
      "Using cached langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "Downloading aiohttp-3.13.2-cp310-cp310-macosx_11_0_arm64.whl (489 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Using cached langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.7.0-cp310-cp310-macosx_11_0_arm64.whl (44 kB)\n",
      "Using cached pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Downloading sqlalchemy-2.0.44-cp310-cp310-macosx_11_0_arm64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.22.0-cp310-cp310-macosx_11_0_arm64.whl (94 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading frozenlist-1.8.0-cp310-cp310-macosx_11_0_arm64.whl (49 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading numpy-2.2.6-cp310-cp310-macosx_14_0_arm64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.4.1-cp310-cp310-macosx_11_0_arm64.whl (47 kB)\n",
      "Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: SQLAlchemy, python-dotenv, propcache, numpy, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, attrs, async-timeout, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-text-splitters, langchain-classic, langchain-community\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/21\u001b[0m [langchain-community]ngchain-community]\n",
      "\u001b[1A\u001b[2KSuccessfully installed SQLAlchemy-2.0.44 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 async-timeout-4.0.3 attrs-25.4.0 dataclasses-json-0.6.7 frozenlist-1.8.0 httpx-sse-0.4.3 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-text-splitters-1.0.0 marshmallow-3.26.1 multidict-6.7.0 mypy-extensions-1.1.0 numpy-2.2.6 propcache-0.4.1 pydantic-settings-2.12.0 python-dotenv-1.2.1 typing-inspect-0.9.0 yarl-1.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain langchain-core langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d8935cd-1fdd-4fe0-bd1a-f902f034c7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Using cached langchain_openai-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain-openai) (1.1.0)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain-openai) (2.8.1)\n",
      "Collecting tiktoken<1.0.0,>=0.7.0 (from langchain-openai)\n",
      "  Downloading tiktoken-0.12.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (0.4.47)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (2.12.4)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langchain-core<2.0.0,>=1.1.0->langchain-openai) (4.15.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (0.25.0)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (4.11.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.0->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.0->langchain-openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.1.0->langchain-openai) (0.4.2)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1.0.0,>=0.7.0->langchain-openai)\n",
      "  Downloading regex-2025.11.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-openai) (2.5.0)\n",
      "Using cached langchain_openai-1.1.0-py3-none-any.whl (84 kB)\n",
      "Downloading tiktoken-0.12.0-cp310-cp310-macosx_11_0_arm64.whl (995 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m995.8/995.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.11.3-cp310-cp310-macosx_11_0_arm64.whl (288 kB)\n",
      "Installing collected packages: regex, tiktoken, langchain-openai\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [langchain-openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langchain-openai-1.1.0 regex-2025.11.3 tiktoken-0.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "074a24d2-257f-4389-80e4-72d6004f6e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (2.8.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from openai) (2.12.4)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /opt/homebrew/anaconda3/envs/langchain/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36ee4310-67a6-4e2c-8ecc-548a5b26ab08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.19\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d06be0eb-0149-42c4-a224-df0dab1d361f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 2.8.1\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: Apache-2.0\n",
      "Location: /opt/homebrew/anaconda3/lib/python3.11/site-packages\n",
      "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a22a4c7",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8f7866",
   "metadata": {},
   "source": [
    "### Use the OpenAI library directly\n",
    "The example below uses the OpenAI Python SDK to interact with a locally hosted open-weight reasoning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1c2fede-4741-4de4-9130-49157c78dfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I’m ChatGPT, a large language model created by OpenAI. I can help answer questions, brainstorm ideas, explain concepts, write stories or code, and chat about almost any topic you’re interested in. I’m here to assist, learn from our conversation, and make your experience as helpful and engaging as possible. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# Method 1 - Use OpenAI Library\n",
    "\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Introduce yourself\"}\n",
    "]\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = \"Local Server, no key\",\n",
    "    base_url = \"http://127.0.0.1:1234/v1\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model = \"gpt-oss-20b\",\n",
    "    temperature = 0,\n",
    "    messages = messages,\n",
    "    stream = False\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33606ae9",
   "metadata": {},
   "source": [
    "### Use LangChain\n",
    "The example below uses LangChain to build a simple chain that chats with a locally hosted model, instructs it to return comma-separated values, and then parses the output into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c461d768-7056-4c95-838e-25bf362e276a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed names: ['Wei', 'Jun', 'Ming', 'Hao', 'Jie']\n"
     ]
    }
   ],
   "source": [
    "# Method 2 - Use LangChain\n",
    "\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-oss-20b\",\n",
    "    api_key = \"Local Server, no key\",\n",
    "    base_url = \"http://127.0.0.1:1234/v1\",\n",
    "    verbose = False\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Give me 5 popular names in {country} for {gender}. Return the result in comma separated, no other text.\"\n",
    ")\n",
    "\n",
    "chain = prompt | llm | CommaSeparatedListOutputParser()\n",
    "\n",
    "response = chain.invoke({\"country\": \"China\", \"gender\": \"male\" })\n",
    "\n",
    "print(f\"Proposed names: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97808d8",
   "metadata": {},
   "source": [
    "### Use LangChain to parse the response into a Pydantic object\n",
    "Use `PydanticOutputParser` to validate the model’s output and convert it into a structured Pydantic object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5989c0fb-a250-4077-afd1-14569b7829bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"name\": {\"title\": \"Name\", \"type\": \"string\"}, \"age\": {\"title\": \"Age\", \"type\": \"integer\"}}, \"required\": [\"name\", \"age\"]}\n",
      "```\n",
      "name='Alice' age=30\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain_core.prompts import load_prompt\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI # Or your preferred LLM\n",
    "\n",
    "# Define your Pydantic model (as shown above)\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "# Initialize the output parser\n",
    "parser = PydanticOutputParser(pydantic_object=Person)\n",
    "\n",
    "print(parser.get_format_instructions())\n",
    "\n",
    "# Load the prompt\n",
    "# If the output_parser is defined in the prompt file:\n",
    "# prompt = load_prompt(\"prompt.yaml\")\n",
    "# If not, you need to add format instructions to the prompt:\n",
    "prompt = load_prompt(\"prompt_without_parser_in_file.yaml\") # Using the second example prompt above\n",
    "\n",
    "# Create an LLM instance\n",
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-oss-20b\",\n",
    "    api_key = \"Local Server, no key\",\n",
    "    base_url = \"http://127.0.0.1:1234/v1\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Create a chain\n",
    "chain = (\n",
    "    {\"text\": RunnablePassthrough(), \"format_instructions\": lambda x: parser.get_format_instructions()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# Invoke the chain\n",
    "result = chain.invoke(\"You can call me Alice, and I was born 30 years ago\")\n",
    "print(result)\n",
    "# Expected output: Person(name='Alice', age=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896cb9c2-a6ab-437c-9923-4c13f1f9fafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: mm\n",
      "Explanation:1 mm = 0.1 cm\n",
      "\n",
      "Word: m\n",
      "Explanation:1 m = 100 cm\n",
      "\n",
      "Word: km\n",
      "Explanation:1 km = 1000 m\n",
      "\n",
      "Word: in\n",
      "Explanation:1 in = 2.54 cm\n",
      "\n",
      "Word: ft\n",
      "Explanation:1 ft = 12 in\n",
      "\n",
      "Word: yd\n",
      "Explanation:1 yd = 3 ft\n",
      "\n",
      "Word: mi\n",
      "Explanation:1 mi = 5280 ft\n",
      "\n",
      "Word: g\n",
      "Explanation:1 g = 1000 mg\n",
      "\n",
      "Word: kg\n",
      "Explanation:1 kg = 1000 g\n",
      "\n",
      "Word: mg\n",
      "Explanation:1 mg = 0.001 g\n",
      "\n",
      "Word: lb\n",
      "Explanation:1 lb = 16 oz\n",
      "\n",
      "Word: oz\n",
      "Explanation:1 oz = 28.35 g\n",
      "\n",
      "Word: l\n",
      "Explanation:1 L = 1000 mL\n",
      "\n",
      "Word: ml\n",
      "Explanation:1 mL = 0.001 L\n",
      "\n",
      "Word:gigawatt\n",
      "Return the explanation for this word and show nothing else\n",
      "content='1 gigawatt = 10⁹ watts' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 255, 'prompt_tokens': 282, 'total_tokens': 537, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'gpt-oss-20b', 'system_fingerprint': 'gpt-oss-20b', 'id': 'chatcmpl-enhjf232s36eimksvg7yb', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--63751a7b-64a6-4ffa-8b8d-f87cccf54d80-0' usage_metadata={'input_tokens': 282, 'output_tokens': 255, 'total_tokens': 537, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotPromptTemplate\n",
    "from langchain_core.example_selectors.length_based import LengthBasedExampleSelector\n",
    "from langchain_openai import ChatOpenAI # Or your preferred LLM\n",
    "\n",
    "# Create an LLM instance\n",
    "llm = ChatOpenAI(\n",
    "    model = \"gpt-oss-20b\",\n",
    "    api_key = \"Local Server, no key\",\n",
    "    base_url = \"http://127.0.0.1:1234/v1\",\n",
    "    temperature=0,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "# 50 examples\n",
    "examples = [\n",
    "  {\"input\": \"mm\", \"output\": \"1 mm = 0.1 cm\"},\n",
    "  {\"input\": \"m\", \"output\": \"1 m = 100 cm\"},\n",
    "  {\"input\": \"km\", \"output\": \"1 km = 1000 m\"},\n",
    "  {\"input\": \"in\", \"output\": \"1 in = 2.54 cm\"},\n",
    "  {\"input\": \"ft\", \"output\": \"1 ft = 12 in\"},\n",
    "  {\"input\": \"yd\", \"output\": \"1 yd = 3 ft\"},\n",
    "  {\"input\": \"mi\", \"output\": \"1 mi = 5280 ft\"},\n",
    "  {\"input\": \"g\", \"output\": \"1 g = 1000 mg\"},\n",
    "  {\"input\": \"kg\", \"output\": \"1 kg = 1000 g\"},\n",
    "  {\"input\": \"mg\", \"output\": \"1 mg = 0.001 g\"},\n",
    "  {\"input\": \"lb\", \"output\": \"1 lb = 16 oz\"},\n",
    "  {\"input\": \"oz\", \"output\": \"1 oz = 28.35 g\"},\n",
    "  {\"input\": \"l\", \"output\": \"1 L = 1000 mL\"},\n",
    "  {\"input\": \"ml\", \"output\": \"1 mL = 0.001 L\"},\n",
    "  {\"input\": \"gal\", \"output\": \"1 gal = 3.785 L\"},\n",
    "  {\"input\": \"qt\", \"output\": \"1 qt = 2 pt\"},\n",
    "  {\"input\": \"pt\", \"output\": \"1 pt = 2 cups\"},\n",
    "  {\"input\": \"cup\", \"output\": \"1 cup = 16 tbsp\"},\n",
    "  {\"input\": \"tbsp\", \"output\": \"1 tbsp = 3 tsp\"},\n",
    "  {\"input\": \"tsp\", \"output\": \"1 tsp = 5 mL\"},\n",
    "  {\"input\": \"s\", \"output\": \"1 s = 1000 ms\"},\n",
    "  {\"input\": \"ms\", \"output\": \"1 ms = 0.001 s\"},\n",
    "  {\"input\": \"min\", \"output\": \"1 min = 60 s\"},\n",
    "  {\"input\": \"hr\", \"output\": \"1 hr = 60 min\"},\n",
    "  {\"input\": \"day\", \"output\": \"1 day = 24 hr\"},\n",
    "  {\"input\": \"n\", \"output\": \"1 N = 1 kg·m/s²\"},\n",
    "  {\"input\": \"pa\", \"output\": \"1 Pa = 1 N/m²\"},\n",
    "  {\"input\": \"kpa\", \"output\": \"1 kPa = 1000 Pa\"},\n",
    "  {\"input\": \"mpa\", \"output\": \"1 MPa = 1000 kPa\"},\n",
    "  {\"input\": \"j\", \"output\": \"1 J = 1 N·m\"},\n",
    "  {\"input\": \"kj\", \"output\": \"1 kJ = 1000 J\"},\n",
    "  {\"input\": \"w\", \"output\": \"1 W = 1 J/s\"},\n",
    "  {\"input\": \"kw\", \"output\": \"1 kW = 1000 W\"},\n",
    "  {\"input\": \"c\", \"output\": \"1°C = 33.8°F\"},\n",
    "  {\"input\": \"f\", \"output\": \"1°F = -17.22°C\"},\n",
    "  {\"input\": \"k\", \"output\": \"1 K = -272.15°C\"},\n",
    "  {\"input\": \"bps\", \"output\": \"1 bps = 1 bit/s\"},\n",
    "  {\"input\": \"kbps\", \"output\": \"1 kbps = 1000 bps\"},\n",
    "  {\"input\": \"mbps\", \"output\": \"1 Mbps = 1000 kbps\"},\n",
    "  {\"input\": \"gbps\", \"output\": \"1 Gbps = 1000 Mbps\"},\n",
    "  {\"input\": \"byte\", \"output\": \"1 byte = 8 bits\"},\n",
    "  {\"input\": \"kb\", \"output\": \"1 KB = 1024 bytes\"},\n",
    "  {\"input\": \"mb\", \"output\": \"1 MB = 1024 KB\"},\n",
    "  {\"input\": \"gb\", \"output\": \"1 GB = 1024 MB\"},\n",
    "  {\"input\": \"tb\", \"output\": \"1 TB = 1024 GB\"},\n",
    "  {\"input\": \"rad\", \"output\": \"1 rad = 57.2958°\"},\n",
    "  {\"input\": \"deg\", \"output\": \"1° = 0.01745 rad\"},\n",
    "  {\"input\": \"atm\", \"output\": \"1 atm = 101.325 kPa\"},\n",
    "  {\"input\": \"bar\", \"output\": \"1 bar = 100 kPa\"}\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Word: {input}\\nExplanation:{output}\",\n",
    ")\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=100,         # the length here is number of bytes\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_selector = example_selector,\n",
    "    example_prompt = example_prompt,\n",
    "    suffix=\"Word:{input}\\nReturn the explanation for this word and show nothing else\",\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "print(prompt.format(input=\"gigawatt\"))\n",
    "\n",
    "result = llm.invoke(prompt.format(input=\"gigawatt\"))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35be6d2a-f06a-44ff-ad0d-6295eb421f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
